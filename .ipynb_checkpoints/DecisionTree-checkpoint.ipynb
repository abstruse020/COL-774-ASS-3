{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "8e9b6897-ed48-4994-9d01-45301b1d69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import argv\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm_notebook\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c285b4eb-f476-498a-8fa1-691b9f6c47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables --\n",
    "train_path = 'bank_dataset/bank_train.csv'\n",
    "test_path = 'bank_dataset/bank_test.csv'\n",
    "validate_path = 'bank_dataset/bank_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a4ca60-e697-4980-bc36-0fd333065616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path, sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a97669-9772-43d5-bf80-57efb2bd6e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>890</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>5</td>\n",
       "      <td>feb</td>\n",
       "      <td>343</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2558</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>19</td>\n",
       "      <td>jun</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>267</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>21</td>\n",
       "      <td>nov</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>4567</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>31</td>\n",
       "      <td>jul</td>\n",
       "      <td>921</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>5887</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>2</td>\n",
       "      <td>jun</td>\n",
       "      <td>181</td>\n",
       "      <td>3</td>\n",
       "      <td>293</td>\n",
       "      <td>2</td>\n",
       "      <td>failure</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         job  marital  education default  balance housing loan  \\\n",
       "0   57  unemployed  married  secondary      no      890      no   no   \n",
       "1   56  technician  married  secondary      no     2558      no   no   \n",
       "2   50  technician  married   tertiary      no      267     yes   no   \n",
       "3   47  management  married    unknown      no     4567      no   no   \n",
       "4   49  management  married   tertiary      no     5887      no   no   \n",
       "\n",
       "     contact  day month  duration  campaign  pdays  previous poutcome    y  \n",
       "0   cellular    5   feb       343         4     -1         0  unknown   no  \n",
       "1    unknown   19   jun       288         1     -1         0  unknown   no  \n",
       "2   cellular   21   nov        30         1     -1         0  unknown   no  \n",
       "3  telephone   31   jul       921         4     -1         0  unknown   no  \n",
       "4   cellular    2   jun       181         3    293         2  failure  yes  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = read_data(train_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a831aa-0fb9-430a-84ca-5ce7dc8f06a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36168, 17)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab57feee-1a65-408f-b303-e04e5df4fbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_data.plot(subplots = True, figsize = (10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56d88ce-5e20-4def-8fba-3ae056f06043",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For col: age\n",
      "{18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 94, 95}\n",
      "For col: job\n",
      "{'services', 'management', 'housemaid', 'blue-collar', 'unemployed', 'self-employed', 'technician', 'retired', 'admin.', 'unknown', 'student', 'entrepreneur'}\n",
      "For col: marital\n",
      "{'divorced', 'single', 'married'}\n",
      "For col: education\n",
      "{'secondary', 'primary', 'tertiary', 'unknown'}\n",
      "For col: default\n",
      "{'yes', 'no'}\n",
      "For col: housing\n",
      "{'yes', 'no'}\n",
      "For col: loan\n",
      "{'yes', 'no'}\n",
      "For col: contact\n",
      "{'unknown', 'telephone', 'cellular'}\n",
      "For col: day\n",
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31}\n",
      "For col: month\n",
      "{'dec', 'feb', 'may', 'nov', 'sep', 'oct', 'jul', 'jan', 'aug', 'mar', 'jun', 'apr'}\n",
      "For col: campaign\n",
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 44, 46, 50, 51, 55, 58, 63}\n",
      "For col: pdays\n",
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 397, 398, 399, 401, 403, 405, 407, 409, 410, 411, 412, 413, 414, 415, 416, 417, 420, 421, 422, 424, 425, 426, 427, 428, 430, 431, 432, 433, 434, 435, 436, 439, 440, 442, 445, 446, 449, 450, 452, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 469, 470, 472, 474, 475, 477, 478, 479, 481, 484, 485, 486, 490, 491, 493, 495, 500, 503, 504, 508, 511, 514, 515, 520, 521, 524, 526, 528, 529, 530, 531, 535, 536, 541, 542, 543, 547, 551, 555, 557, 558, 561, 562, 579, 585, 586, 589, 592, 594, 616, 626, 633, 648, 651, 655, 656, 667, 670, 674, 680, 683, 687, 690, 701, 717, 728, 745, 749, 760, 769, 771, 772, 775, 776, 778, 779, 782, 784, 791, 792, 805, 808, 826, 838, 842, 854, 871, -1}\n",
      "For col: previous\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 275, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 35, 37, 38, 40, 41, 51, 55, 58, 21}\n",
      "For col: poutcome\n",
      "{'unknown', 'success', 'failure', 'other'}\n",
      "For col: y\n",
      "{'yes', 'no'}\n"
     ]
    }
   ],
   "source": [
    "for col in train_data.columns:\n",
    "    if col == 'balance' or col == 'duration':\n",
    "        continue\n",
    "    print('For col:',col)\n",
    "    print(set(train_data[col].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "a9ce05cb-72a4-475a-b654-2281dcab7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = {}\n",
    "binary_columns = ['default', 'housing', 'loan']\n",
    "def make_one_hot_encoding(data, cols):\n",
    "    Y = data['y']\n",
    "    data.drop('y', axis = 'columns', inplace = True)\n",
    "    for col in cols:\n",
    "        append_data = pd.get_dummies(data[col])\n",
    "        ohe_columns[col] = append_data.columns\n",
    "        for new_col in append_data.columns:\n",
    "            data[col +'.'+ str(new_col)] = append_data[new_col]\n",
    "        data.drop(col, axis = 'columns', inplace = True)\n",
    "    data['y'] = Y\n",
    "    for b_col in binary_columns:\n",
    "        data[b_col] = data[b_col] == 'yes'\n",
    "    return data\n",
    "\n",
    "def apply_one_hot_encoding(data, cols):\n",
    "    Y = data['y']\n",
    "    data.drop('y', axis = 'columns', inplace = True)\n",
    "    for col in cols:\n",
    "        for new_col in ohe_columns[col]:\n",
    "            data[col + '.' + str(new_col)] = data[col] == new_col\n",
    "        data.drop(col, axis = 'columns', inplace = True)\n",
    "    data['y'] = Y\n",
    "    for b_col in binary_columns:\n",
    "        data[b_col] = data[b_col] == 'yes'\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2f9abc6a-afb0-45c5-8be8-67b0412f0e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ohe_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "310134f9-fffd-43b0-9168-0625dfd114c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ohe_test_data.loc[ohe_test_data['age'] == 34, 'age']\n",
    "# ohe_test_data['age.35'] = ohe_test_data['age'] == 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f23bc7b1-0796-4531-8476-e42aba32259e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ohe_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8f681-c194-45d3-93ff-4371c6843872",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Main reading starts from here -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "142ca6ee-aa3d-4c1e-bcb8-c1373a83502c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non categorical or biary cols {'balance', 'loan', 'pdays', 'day', 'duration', 'y', 'default', 'age', 'previous', 'housing'}\n",
      "(36168, 17)\n",
      "(36168, 95)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job.admin.</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign.50</th>\n",
       "      <th>campaign.51</th>\n",
       "      <th>campaign.55</th>\n",
       "      <th>campaign.58</th>\n",
       "      <th>campaign.63</th>\n",
       "      <th>poutcome.failure</th>\n",
       "      <th>poutcome.other</th>\n",
       "      <th>poutcome.success</th>\n",
       "      <th>poutcome.unknown</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>890</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>343</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "      <td>2558</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>288</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>267</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "      <td>4567</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>921</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "      <td>5887</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>181</td>\n",
       "      <td>293</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  default  balance  housing   loan  day  duration  pdays  previous  \\\n",
       "0   57    False      890    False  False    5       343    999         0   \n",
       "1   56    False     2558    False  False   19       288    999         0   \n",
       "2   50    False      267     True  False   21        30    999         0   \n",
       "3   47    False     4567    False  False   31       921    999         0   \n",
       "4   49    False     5887    False  False    2       181    293         2   \n",
       "\n",
       "   job.admin.  ...  campaign.50  campaign.51  campaign.55  campaign.58  \\\n",
       "0           0  ...            0            0            0            0   \n",
       "1           0  ...            0            0            0            0   \n",
       "2           0  ...            0            0            0            0   \n",
       "3           0  ...            0            0            0            0   \n",
       "4           0  ...            0            0            0            0   \n",
       "\n",
       "   campaign.63  poutcome.failure  poutcome.other  poutcome.success  \\\n",
       "0            0                 0               0                 0   \n",
       "1            0                 0               0                 0   \n",
       "2            0                 0               0                 0   \n",
       "3            0                 0               0                 0   \n",
       "4            0                 1               0                 0   \n",
       "\n",
       "   poutcome.unknown    y  \n",
       "0                 1   no  \n",
       "1                 1   no  \n",
       "2                 1   no  \n",
       "3                 1   no  \n",
       "4                 0  yes  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Read data and make one hot vectors\n",
    "train_data = read_data(train_path)\n",
    "n_categorical_cols = ['job', 'marital', 'education', 'contact', 'month', 'campaign', 'poutcome']\n",
    "print('non categorical or biary cols',set(train_data.columns) - set(n_categorical_cols))\n",
    "std_train_data = train_data.copy(deep=True)\n",
    "\n",
    "ohe_train_data = make_one_hot_encoding(train_data, n_categorical_cols)\n",
    "ohe_train_data.loc[ohe_train_data['pdays'] == -1, 'pdays'] = 999\n",
    "print(std_train_data.shape)\n",
    "print(ohe_train_data.shape)\n",
    "ohe_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9c5411c4-6749-45d4-a857-f4c26a7547f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test std shape       : (4521, 17)\n",
      "test ohe shape       : (4521, 95)\n",
      "validation std shape : (4522, 17)\n",
      "validation ohe shape : (4522, 95)\n"
     ]
    }
   ],
   "source": [
    "test_data = read_data(test_path)\n",
    "vali_data = read_data(validate_path)\n",
    "std_test_data = test_data.copy(deep=True)\n",
    "std_vali_data = vali_data.copy(deep=True)\n",
    "\n",
    "ohe_test_data = apply_one_hot_encoding(test_data, n_categorical_cols)\n",
    "ohe_test_data.loc[ohe_test_data['pdays'] == -1, 'pdays'] = 999\n",
    "ohe_vali_data = apply_one_hot_encoding(vali_data, n_categorical_cols)\n",
    "ohe_vali_data.loc[ohe_vali_data['pdays'] == -1, 'pdays'] = 999\n",
    "\n",
    "print('test std shape       :',std_test_data.shape)\n",
    "print('test ohe shape       :',ohe_test_data.shape)\n",
    "print('validation std shape :',std_vali_data.shape)\n",
    "print('validation ohe shape :',ohe_vali_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c585f7-a404-4329-a72f-180fea868740",
   "metadata": {},
   "source": [
    "### Changing numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2a2a5fa1-dc7c-4579-94fe-5e75f6d4952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['age', 'balance', 'day', 'duration','pdays', 'previous']\n",
    "# data_medians = ohe_train_data[numerical_cols].median(axis = 0)\n",
    "# for col in numerical_cols:\n",
    "#     train_data[col] = ohe_train_data[col] > data_medians[col]\n",
    "# ohe_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "287fa09b-b98e-4678-876f-270dd49c8a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# numerical_cols = ['age', 'balance', 'day', 'duration','pdays', 'previous']\n",
    "# medians = train_data[numerical_cols].median(axis=0)\n",
    "# print(medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e6f49ffd-f07a-4e54-94be-357211bec4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Not useful\n",
    "# # Delete it\n",
    "# def split_on_median(data, col):\n",
    "#     med = np.median(data[col])\n",
    "#     print('\\n\\nmedian', med)\n",
    "#     #data[data[col] > med]\n",
    "#     data.loc[:,col] = data.loc[:,col] > med\n",
    "#     return data, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "dfed971b-9653-4e30-aff0-ec2b1e4d5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    m = data.shape[0]\n",
    "    negative_data = data[data['y'] == 'no'].shape[0]\n",
    "    positive_data = data[data['y'] == 'yes'].shape[0]\n",
    "    if negative_data == 0 or positive_data == 0:\n",
    "        return 0\n",
    "    ent = (positive_data/m)*np.log2(m/positive_data) + (negative_data/m)*np.log2(m/negative_data)\n",
    "    return ent\n",
    "# entropy(ohe_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1a774685-93ab-4a8c-86b2-2994af497d71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal col values\n",
      "{'age': [True, False], 'job': ['services', 'management', 'housemaid', 'blue-collar', 'unemployed', 'self-employed', 'technician', 'retired', 'admin.', 'unknown', 'student', 'entrepreneur'], 'marital': ['divorced', 'single', 'married'], 'education': ['secondary', 'primary', 'tertiary', 'unknown'], 'default': ['yes', 'no'], 'balance': [True, False], 'housing': ['yes', 'no'], 'loan': ['yes', 'no'], 'contact': ['unknown', 'telephone', 'cellular'], 'day': [True, False], 'month': ['dec', 'feb', 'may', 'nov', 'sep', 'oct', 'jul', 'jan', 'aug', 'mar', 'jun', 'apr'], 'duration': [True, False], 'campaign': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 44, 46, 50, 51, 55, 58, 63], 'pdays': [True, False], 'previous': [True, False], 'poutcome': ['unknown', 'success', 'failure', 'other'], 'y': ['yes', 'no']}\n",
      "Ohe encoded col values\n",
      "{'age': [True, False], 'default': [False, True], 'balance': [True, False], 'housing': [False, True], 'loan': [False, True], 'day': [True, False], 'duration': [True, False], 'pdays': [True, False], 'previous': [True, False], 'job.admin.': [0, 1], 'job.blue-collar': [0, 1], 'job.entrepreneur': [0, 1], 'job.housemaid': [0, 1], 'job.management': [0, 1], 'job.retired': [0, 1], 'job.self-employed': [0, 1], 'job.services': [0, 1], 'job.student': [0, 1], 'job.technician': [0, 1], 'job.unemployed': [0, 1], 'job.unknown': [0, 1], 'marital.divorced': [0, 1], 'marital.married': [0, 1], 'marital.single': [0, 1], 'education.primary': [0, 1], 'education.secondary': [0, 1], 'education.tertiary': [0, 1], 'education.unknown': [0, 1], 'contact.cellular': [0, 1], 'contact.telephone': [0, 1], 'contact.unknown': [0, 1], 'month.apr': [0, 1], 'month.aug': [0, 1], 'month.dec': [0, 1], 'month.feb': [0, 1], 'month.jan': [0, 1], 'month.jul': [0, 1], 'month.jun': [0, 1], 'month.mar': [0, 1], 'month.may': [0, 1], 'month.nov': [0, 1], 'month.oct': [0, 1], 'month.sep': [0, 1], 'campaign.1': [0, 1], 'campaign.2': [0, 1], 'campaign.3': [0, 1], 'campaign.4': [0, 1], 'campaign.5': [0, 1], 'campaign.6': [0, 1], 'campaign.7': [0, 1], 'campaign.8': [0, 1], 'campaign.9': [0, 1], 'campaign.10': [0, 1], 'campaign.11': [0, 1], 'campaign.12': [0, 1], 'campaign.13': [0, 1], 'campaign.14': [0, 1], 'campaign.15': [0, 1], 'campaign.16': [0, 1], 'campaign.17': [0, 1], 'campaign.18': [0, 1], 'campaign.19': [0, 1], 'campaign.20': [0, 1], 'campaign.21': [0, 1], 'campaign.22': [0, 1], 'campaign.23': [0, 1], 'campaign.24': [0, 1], 'campaign.25': [0, 1], 'campaign.26': [0, 1], 'campaign.27': [0, 1], 'campaign.28': [0, 1], 'campaign.29': [0, 1], 'campaign.30': [0, 1], 'campaign.31': [0, 1], 'campaign.32': [0, 1], 'campaign.33': [0, 1], 'campaign.34': [0, 1], 'campaign.35': [0, 1], 'campaign.36': [0, 1], 'campaign.37': [0, 1], 'campaign.38': [0, 1], 'campaign.39': [0, 1], 'campaign.41': [0, 1], 'campaign.44': [0, 1], 'campaign.46': [0, 1], 'campaign.50': [0, 1], 'campaign.51': [0, 1], 'campaign.55': [0, 1], 'campaign.58': [0, 1], 'campaign.63': [0, 1], 'poutcome.failure': [0, 1], 'poutcome.other': [0, 1], 'poutcome.success': [0, 1], 'poutcome.unknown': [0, 1], 'y': ['yes', 'no']}\n"
     ]
    }
   ],
   "source": [
    "std_col_val_set = {}\n",
    "for col in std_train_data.columns:\n",
    "    if col in numerical_cols:\n",
    "        std_col_val_set[col] = [True, False]\n",
    "    else:\n",
    "        std_col_val_set[col] = list(set(std_train_data[col].values))\n",
    "print('normal col values')\n",
    "print(std_col_val_set)\n",
    "\n",
    "ohe_col_val_set = {}\n",
    "for col in ohe_train_data.columns:\n",
    "    if col in numerical_cols:\n",
    "        ohe_col_val_set[col] = [True, False]\n",
    "    else:\n",
    "        ohe_col_val_set[col] = list(set(ohe_train_data[col].values))\n",
    "print('Ohe encoded col values')\n",
    "print(ohe_col_val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "bd9bd9a7-0799-4eaa-8f35-759be09301e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_gain(attr, data):\n",
    "    m = data.shape[0]\n",
    "    if m == 0:\n",
    "        return 0\n",
    "    uniq_values = None\n",
    "    col_median = None\n",
    "    if attr in numerical_cols:\n",
    "        col_median = data[attr].median()\n",
    "        uniq_values = [True, False]\n",
    "    else:\n",
    "        uniq_values = col_val_set[attr]\n",
    "    Hs = []\n",
    "    for val in uniq_values:\n",
    "        sub_data = None\n",
    "        if attr in numerical_cols and val:\n",
    "            sub_data = data[data[attr] > col_median]\n",
    "        elif attr in numerical_cols and not val:\n",
    "            sub_data = data[data[attr] <= col_median]\n",
    "        else:\n",
    "            sub_data = data[data[attr] == val]\n",
    "        if sub_data.shape[0] == 0:\n",
    "            continue\n",
    "        en = entropy(sub_data)\n",
    "        prob = sub_data.shape[0]/m\n",
    "        Hs.append(prob*en)\n",
    "    return np.sum(Hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "75a813f6-404b-4223-909d-cfbcf556a2c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('housing', 0.1444843438056282)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_attr_split(data):\n",
    "    if data.shape[0] == 0:\n",
    "        return None, 0\n",
    "    #print('best attr data',data.shape)\n",
    "    max_ig = 0\n",
    "    best_attr = None\n",
    "    H_y = entropy(data)\n",
    "    #print('entropy of dataset', H_y)\n",
    "    for col in data.columns[:-1]:\n",
    "        ig = H_y - inf_gain(col, data)\n",
    "        #print('Col: %-20s info gain: %f'%(col,ig))\n",
    "        if max_ig < ig:\n",
    "            max_ig = ig\n",
    "            best_attr = col\n",
    "    return best_attr, max_ig\n",
    "# print(ohe_train_data[0:15])\n",
    "col_val_set = ohe_col_val_set\n",
    "best_attr_split(ohe_train_data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f2bc0a3d-6a15-4c51-be01-cfb7993b7b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    total_nodes = 0\n",
    "    def  __init__(self, parent, val=-1, childs = [], attr = None, split_val_parent= None, median = None):\n",
    "        self.parent = parent\n",
    "        self.val = val\n",
    "        self.childs = childs\n",
    "        self.sub_tree_size = 0\n",
    "        self.attr = attr\n",
    "        self.split_val_p = split_val_parent\n",
    "        self.median = median\n",
    "        self.prune_below = False\n",
    "        self.pruning_checked = False\n",
    "        Node.total_nodes += 1\n",
    "    \n",
    "    def __str__(self):\n",
    "        l = len(self.childs)\n",
    "        return 'attr:%-10s, val:%-10s, pruned?:%-5d,p_checked:%d ,#childs:%-5d'%(self.attr,str(self.val),self.prune_below,self.pruning_checked,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "8976bb8b-00ee-4940-bfb8-214f5431031d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# std_train_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ab057e84-ef69-487b-aa95-3f6bf6513270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Decision tree\n",
    "class DecisionTree():\n",
    "    def __init__(self, max_depth=20):\n",
    "        self.max_depth = max_depth\n",
    "        self.prediction_at_depth = []\n",
    "    \n",
    "    def build_tree(self, data, parent = None):\n",
    "        # print('data ------------',data.shape)\n",
    "        median = None\n",
    "        if data.shape[0] == 0:\n",
    "            return None\n",
    "        Y_uniq_vals_len = len(list(set(data['y'].values)))\n",
    "        y_val = data['y'].mode()[0]\n",
    "        if Y_uniq_vals_len <=1:\n",
    "            return Node(parent = parent, val = y_val, childs = [], attr='leaf')\n",
    "        split_attr, max_ig = best_attr_split(data)\n",
    "        if split_attr == None:\n",
    "            print('\\n\\n no values to split')\n",
    "            print(data.shape)\n",
    "            print(data)\n",
    "            return Node(parent = parent, val = y_val, childs = [], attr='leaf')\n",
    "        if max_ig < 0:\n",
    "            print('\\n\\n negative ig max')\n",
    "            print(data.shape)\n",
    "            print(data)\n",
    "            return None\n",
    "\n",
    "        if split_attr in numerical_cols:\n",
    "            median = data[split_attr].median()\n",
    "        \n",
    "        values_to_split = col_val_set[split_attr]\n",
    "\n",
    "        node = Node(parent=parent,val=y_val,childs=[],attr=split_attr, median=median)\n",
    "        node.sub_tree_size = 1\n",
    "        # print('Attr:',split_attr)\n",
    "        for split_val in values_to_split:\n",
    "            # If and elif --it's a numirical attribute, els -- for categorical\n",
    "            # print('split value:',split_val)\n",
    "            if median != None and split_val == True:\n",
    "                # print('more than median')\n",
    "                # print('median',median)\n",
    "                child = self.build_tree(data[data[split_attr] > median], node)\n",
    "            elif median != None and split_val == False:\n",
    "                # print('less then median')\n",
    "                child = self.build_tree(data[data[split_attr] <= median], node)\n",
    "            else:\n",
    "                # print('no categorical')\n",
    "                child = self.build_tree(data[data[split_attr] == split_val], node)\n",
    "            \n",
    "            if child != None:\n",
    "                child.split_val_p = split_val\n",
    "                node.childs.append(child)\n",
    "                node.sub_tree_size += child.sub_tree_size\n",
    "        # print('returning for node',node)\n",
    "        return node\n",
    "    \n",
    "    def predict_a_point(self, row, node, depth = 0, max_depth = 50, consider_pruning = False, prune_it = False):\n",
    "        #print('For row  :',row.head())\n",
    "        if node == None:\n",
    "            print(\"\\n\\n\\nNode became none-----------------------------\")\n",
    "            return 0\n",
    "        if 'y' in row:\n",
    "            pred = 1 if node.val == row['y'] else 0\n",
    "            self.prediction_at_depth.append(pred)\n",
    "            \n",
    "        if consider_pruning and node.prune_below:\n",
    "            return node.val\n",
    "        \n",
    "        if len(node.childs) < 1 or node.attr == 'leaf' or depth >= max_depth:\n",
    "            return node.val\n",
    "        attribute = node.attr\n",
    "        # print('Attribute : %s'%(attribute))\n",
    "    #     print('node      : %s'%(node))\n",
    "        if attribute in numerical_cols:\n",
    "    #         print('\\tnumerical attr')\n",
    "    #         print('\\trows attr value : %-10s'%str(row[attribute]))\n",
    "            if row[attribute] > node.median:\n",
    "                return self.predict_a_point(row, node.childs[0], depth+1, max_depth, consider_pruning, prune_it)\n",
    "            else:\n",
    "                return self.predict_a_point(row, node.childs[1], depth+1, max_depth, consider_pruning, prune_it)\n",
    "        else:\n",
    "    #         print('\\tnon-numerical attr')\n",
    "            for child in node.childs:\n",
    "    #             print('No. childs:',len(node.childs))\n",
    "    #             print('\\tChild:',child)\n",
    "                if row[attribute] == child.split_val_p:\n",
    "                    return self.predict_a_point(row, child, depth+1, max_depth, consider_pruning, prune_it)\n",
    "        #print('New Attribute val found ----------------------------')\n",
    "        #print('suggested value by node:', node.val)\n",
    "        return node.val\n",
    "    \n",
    "    def predict(self,tree, data, consider_pruning = False):\n",
    "        predictions = []\n",
    "        depth_wise_predictions = []\n",
    "        max_depth_pred = 0\n",
    "        for index, row in data.iterrows():\n",
    "            self.prediction_at_depth = []\n",
    "            predictions.append(self.predict_a_point(row, tree, consider_pruning=consider_pruning))\n",
    "            \n",
    "            if len(self.prediction_at_depth) > max_depth_pred:\n",
    "                max_depth_pred = len(self.prediction_at_depth)\n",
    "            \n",
    "            depth_wise_predictions.append(self.prediction_at_depth)\n",
    "        \n",
    "        depth_pred = np.zeros((len(depth_wise_predictions), max_depth_pred))\n",
    "        for i in range(depth_pred.shape[0]):\n",
    "            for j in range(depth_pred.shape[1]):\n",
    "                if len(depth_wise_predictions[i]) > j:\n",
    "                    depth_pred[i,j] = depth_wise_predictions[i][j]\n",
    "                else:\n",
    "                    depth_pred[i,j] = depth_pred[i,j-1]\n",
    "                #print(depth_pred[i,j], end = ' ')\n",
    "            #print()\n",
    "        depth_wise_predictions = [0]*max_depth_pred\n",
    "        for d in range(max_depth_pred):\n",
    "            depth_wise_predictions[d] = sum(depth_pred[:,d])*100/data.shape[0]\n",
    "\n",
    "        return predictions, depth_wise_predictions\n",
    "    \n",
    "    def set_prune_values(self, row, node, depth = 0, max_depth = 50, prune_it = False):\n",
    "        #print('For row  :',row.head())\n",
    "        if node == None:\n",
    "            print(\"\\n\\n\\nNode became none-----------------------------\")\n",
    "            return 0\n",
    "        pred = 1 if node.val == row['y'] else 0\n",
    "        self.prediction_at_depth.append(pred)\n",
    "        \n",
    "        if pred == 1 and not node.pruning_checked:\n",
    "            #print('pruning')\n",
    "            node.prune_below = True\n",
    "            #print('\\t',node)\n",
    "            return node.val\n",
    "        \n",
    "        else:\n",
    "            #print('rem prune')\n",
    "            node.prune_below = False\n",
    "            node.pruning_checked = True\n",
    "        \n",
    "        if len(node.childs)<1 or node.attr == 'leaf' or depth >= max_depth:\n",
    "            return node.val\n",
    "        \n",
    "        attribute = node.attr\n",
    "        \n",
    "        # print('Attribute : %s'%(attribute))\n",
    "    #     print('node      : %s'%(node))\n",
    "        if attribute in numerical_cols:\n",
    "    #         print('\\tnumerical attr')\n",
    "    #         print('\\trows attr value : %-10s'%str(row[attribute]))\n",
    "            if row[attribute] > node.median:\n",
    "                return self.set_prune_values(row, node.childs[0], depth+1, max_depth)\n",
    "            else:\n",
    "                return self.set_prune_values(row, node.childs[1], depth+1, max_depth)\n",
    "        else:\n",
    "    #         print('\\tnon-numerical attr')\n",
    "            for child in node.childs:\n",
    "    #             print('No. childs:',len(node.childs))\n",
    "    #             print('\\tChild:',child)\n",
    "                if row[attribute] == child.split_val_p:\n",
    "                    return self.set_prune_values(row, child, depth+1, max_depth)\n",
    "        \n",
    "        #print('New Attribute val found ----------------------------')\n",
    "        return node.val\n",
    "    \n",
    "    def dfs_tree(self, node, d =0):\n",
    "        if node != None:\n",
    "            if node.prune_below == True and node.attr != 'leaf':\n",
    "                print('pruned node at depth:%d'%(d))\n",
    "                print(node)\n",
    "        for child in node.childs:\n",
    "            self.dfs_tree(child, d+1)\n",
    "        return None\n",
    "    \n",
    "    ## Reduced Error Pruning -->\n",
    "    def prune_tree(self, tree, data):\n",
    "        predictions = []\n",
    "        for index, row in data.iterrows():\n",
    "            predictions.append(self.set_prune_values(row, tree))\n",
    "        print('pruning done')\n",
    "        return predictions\n",
    "    \n",
    "    def count_depth(self, node, d = 0,node_count=0, count_pruned = True):\n",
    "        d_s = [d]\n",
    "        node_count +=1\n",
    "        if node.prune_below and not count_pruned:\n",
    "            return d\n",
    "        for child in node.childs:\n",
    "            d_local = self.count_depth(child, d+1, node_count, count_pruned)\n",
    "            d_s.append(d_local)\n",
    "        return np.max(d_s)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "55cb135b-42d8-4141-ac4f-ef3c9d63ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a422ff-0aa2-443a-80e5-c9678b10fa76",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Global Variables --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ac35893a-a224-41e8-b778-e1915207598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_val_set = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508e7316-a02a-47d1-846f-a0ed5ab45423",
   "metadata": {},
   "source": [
    "### Exec to make decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ff83eb58-83b2-4aa6-891c-b718dccb60b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken 0:00:03.997715\n"
     ]
    }
   ],
   "source": [
    "## Standard split for each uniq categorical values\n",
    "t1 = datetime.datetime.now()\n",
    "d_tree = DecisionTree()\n",
    "col_val_set = std_col_val_set\n",
    "std_tree_root = d_tree.build_tree(std_train_data[:1000])\n",
    "t2 = datetime.datetime.now()\n",
    "print('time taken',t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "69c46943-aacd-4dbc-9d3f-6f03179b4c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken 0:00:01.402862\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "d_tree = DecisionTree()\n",
    "col_val_set = ohe_col_val_set\n",
    "ohe_tree_root = d_tree.build_tree(ohe_train_data[:100])\n",
    "t2 = datetime.datetime.now()\n",
    "print('time taken',t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0972f-e576-4496-bb88-ea8a8a9d3174",
   "metadata": {},
   "source": [
    "### Prediction for train, test and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "41daed61-486a-4bfa-8dee-cf26aac72100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Normal train: [87.0, 90.0, 89.0, 92.0, 93.0, 96.0, 99.0, 100.0]\n",
      "For Ohe Train: [87.0, 90.0, 90.0, 90.0, 90.0, 95.0, 95.0, 98.0, 99.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "_, std_train_acc = d_tree.predict(std_tree_root, std_train_data[:100])\n",
    "print('For Normal train:',std_train_acc)\n",
    "\n",
    "\n",
    "_, ohe_train_acc = d_tree.predict(ohe_tree_root, ohe_train_data[:100])\n",
    "print('For Ohe Train:',ohe_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ed339610-b884-4baf-a852-6166cdb472bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy       : [87.52488387524883, 87.70183587701835, 87.54700287547003, 86.86131386861314, 84.71577084715771, 83.67617783676178, 82.85777482857775, 82.41539482415395]\n",
      "validatoin accuracy : [88.61123396727112, 88.52277753206546, 88.52277753206546, 88.52277753206546, 88.52277753206546, 87.26227333038479, 87.26227333038479, 84.984520123839, 83.61344537815125, 84.29898275099514]\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = d_tree.predict(std_tree_root, std_test_data[:])\n",
    "print('test accuracy       :',test_acc)\n",
    "\n",
    "_, vali_acc = d_tree.predict(ohe_tree_root, ohe_vali_data[:])\n",
    "print('validatoin accuracy :',vali_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e565f4-43e3-4864-9e28-303b27f227d9",
   "metadata": {},
   "source": [
    "### Pruning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ffd3ce45-421e-4e5d-9430-615d7bcba29c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruning done\n",
      "pruning done\n"
     ]
    }
   ],
   "source": [
    "_ = d_tree.prune_tree(std_tree_root, std_vali_data[:1000])\n",
    "_ = d_tree.prune_tree(ohe_tree_root, ohe_vali_data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d9e84458-4e2e-4ea4-9341-53a5b7f31589",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned node at depth:3\n",
      "attr:loan      , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:3\n",
      "attr:age       , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:2\n",
      "attr:poutcome  , val:no        , pruned?:1    ,p_checked:0 ,#childs:4    \n",
      "pruned node at depth:4\n",
      "attr:job       , val:no        , pruned?:1    ,p_checked:0 ,#childs:7    \n",
      "pruned node at depth:5\n",
      "attr:education , val:no        , pruned?:1    ,p_checked:0 ,#childs:4    \n",
      "pruned node at depth:4\n",
      "attr:marital   , val:no        , pruned?:1    ,p_checked:0 ,#childs:3    \n",
      "pruned node at depth:6\n",
      "attr:balance   , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:4\n",
      "attr:housing   , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:4\n",
      "attr:education , val:no        , pruned?:1    ,p_checked:0 ,#childs:3    \n",
      "pruned node at depth:4\n",
      "attr:age       , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:4\n",
      "attr:balance   , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:2\n",
      "attr:marital   , val:no        , pruned?:1    ,p_checked:0 ,#childs:3    \n",
      "pruned node at depth:2\n",
      "attr:contact   , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:2\n",
      "attr:age       , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:2\n",
      "attr:housing   , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:2\n",
      "attr:job       , val:yes       , pruned?:1    ,p_checked:0 ,#childs:4    \n",
      "pruned node at depth:2\n",
      "attr:education , val:no        , pruned?:1    ,p_checked:0 ,#childs:3    \n",
      "pruned node at depth:2\n",
      "attr:age       , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:2\n",
      "attr:age       , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:2\n",
      "attr:age       , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:5\n",
      "attr:age       , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:3\n",
      "attr:campaign  , val:no        , pruned?:1    ,p_checked:0 ,#childs:4    \n",
      "pruned node at depth:4\n",
      "attr:marital   , val:yes       , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:4\n",
      "attr:education , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:2\n",
      "attr:age       , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:3\n",
      "attr:age       , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n",
      "pruned node at depth:2\n",
      "attr:duration  , val:no        , pruned?:1    ,p_checked:0 ,#childs:2    \n"
     ]
    }
   ],
   "source": [
    "d_tree.dfs_tree(std_tree_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "324ac5ee-c027-4219-9148-f0e29b8121c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Accuracy for Trained\n",
      "\tFor standard data : [87.0, 90.0, 89.0, 92.0, 92.0, 95.0, 95.0]\n",
      "\tFor OHE data      : [87.0, 90.0, 90.0, 90.0, 90.0, 95.0, 95.0, 98.0, 99.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "print('Pruned Accuracy for Trained')\n",
    "_, std_pruned_train_acc = d_tree.predict(std_tree_root, std_train_data[:100], consider_pruning=True)\n",
    "print('\\tFor standard data :',std_pruned_train_acc)\n",
    "\n",
    "_, ohe_pruned_train_acc = d_tree.predict(ohe_tree_root, ohe_train_data[:100], consider_pruning=True)\n",
    "print('\\tFor OHE data      :',ohe_pruned_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "6cecd297-e050-4d6a-8f48-3a784974f11b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Accuracy for Test\n",
      "\tFor standard data : [90.0, 90.0, 90.0, 91.0, 86.0, 85.0]\n",
      "\tFor OHE data      : [90.0, 89.0, 89.0, 89.0, 89.0, 90.0, 90.0, 87.0, 84.0, 84.0]\n"
     ]
    }
   ],
   "source": [
    "print('Pruned Accuracy for Test')\n",
    "_, std_pruned_test_acc = d_tree.predict(std_tree_root, std_test_data[:100], consider_pruning=True)\n",
    "print('\\tFor standard data :',std_pruned_test_acc)\n",
    "\n",
    "_, ohe_pruned_test_acc = d_tree.predict(ohe_tree_root, ohe_test_data[:100], consider_pruning=True)\n",
    "print('\\tFor OHE data      :',ohe_pruned_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "6d71729f-8c92-4ea6-af23-3b89ac48b157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned Accuracy for Validation\n",
      "\tFor standard data : [87.0, 86.0, 86.0, 88.0, 87.0, 87.0, 86.0]\n",
      "\tFor OHE data      : [87.0, 86.0, 86.0, 86.0, 86.0, 82.0, 82.0, 81.0, 80.0, 80.0]\n"
     ]
    }
   ],
   "source": [
    "print('Pruned Accuracy for Validation')\n",
    "_, std_pruned_vali_acc = d_tree.predict(std_tree_root, std_vali_data[:100], consider_pruning=True)\n",
    "print('\\tFor standard data :',std_pruned_vali_acc)\n",
    "\n",
    "_, ohe_pruned_vali_acc = d_tree.predict(ohe_tree_root, ohe_vali_data[:100], consider_pruning=True)\n",
    "print('\\tFor OHE data      :',ohe_pruned_vali_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614fb927-7f7e-42b2-9263-1764f7b384eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17e0f8-bab4-447d-a27d-c2f0be564f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf84a657-e4be-4bdc-b44e-d9ec410b886c",
   "metadata": {},
   "source": [
    "### For Part c--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "a3354ad3-f5be-41c3-a73a-e47a51241641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ests            : [ 50 150 250 350 450]\n",
      "max features      : [0.1 0.3 0.5 0.7 0.9]\n",
      "min samples split : [ 2  4  6  8 10]\n"
     ]
    }
   ],
   "source": [
    "n_estimators = np.array(range(50, 451, 100))\n",
    "print('n_ests            :',n_estimators)\n",
    "max_features = np.array(range(1, 11,2))/10\n",
    "print('max features      :',max_features)\n",
    "min_samples_split = np.array(range(2,12,2))\n",
    "print('min samples split :',min_samples_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ca3afc7c-649a-4ceb-b0bf-634f87c62946",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36168, 94) (36168,)\n",
      "CPU times: user 36.1 s, sys: 19.8 ms, total: 36.2 s\n",
      "Wall time: 36.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=50, max_features=0.5, min_samples_split=6,\n",
       "                       n_estimators=250)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# also try with gini (using entropy)\n",
    "d = 50\n",
    "n_est = 250\n",
    "min_s_s = 6\n",
    "max_f = 0.5\n",
    "rfc = RandomForestClassifier(n_estimators=n_est ,max_depth=d,min_samples_split=min_s_s, max_features = max_f)\n",
    "cols_not_y = ohe_train_data.columns[:-1]\n",
    "# print(cols_not_y)\n",
    "X = ohe_train_data.loc[:,cols_not_y]\n",
    "Y = ohe_train_data['y'] == 'yes'\n",
    "print(X.shape, Y.shape)\n",
    "rfc.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f2fcef57-4826-4d53-b933-721cd478655a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9057938965059709\n"
     ]
    }
   ],
   "source": [
    "Y = ohe_vali_data['y'] == 'yes'\n",
    "predict = rfc.predict(ohe_vali_data.loc[:, cols_not_y])\n",
    "acc = accuracy_score(np.array(Y), np.array(predict, dtype=int))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900345d3-a9a8-4663-8bc2-1de87a8bcae1",
   "metadata": {},
   "source": [
    "## def part_c_random_forest():\n",
    "    cols_not_y = ohe_train_data.columns[:-1]\n",
    "    X_train = ohe_train_data.loc[:, cols_not_y]\n",
    "    Y_train = ohe_train_data['y'] == 'yes'\n",
    "    X_test  = ohe_test_data.loc[:, cols_not_y]\n",
    "    Y_test  = ohe_test_data['y'] == 'yes'\n",
    "    X_vali  = ohe_vali_data.loc[:, cols_not_y]\n",
    "    Y_vali  = ohe_vali_data['y'] == 'yes'\n",
    "    \n",
    "    d = 50\n",
    "    n_estimators = np.array(range(50, 451, 100))\n",
    "    max_features = np.array(range(1, 11,2))/10\n",
    "    min_samples_split = np.array(range(2,12,2))\n",
    "    # print('n_ests            :',n_estimators)\n",
    "    # print('max features      :',max_features)\n",
    "    # print('min samples split :',min_samples_split)\n",
    "    best_n_est    = 50\n",
    "    best_max_f    = 0.3\n",
    "    best_min_s_s  = 8\n",
    "    best_accuracy = 0\n",
    "    best_model    = None\n",
    "    for n_est in n_estimators:\n",
    "        for max_f in max_features:\n",
    "            for min_s_s in min_samples_split:\n",
    "                print('itr')\n",
    "                rfc = RandomForestClassifier(n_estimators=n_est ,max_depth=d,min_samples_split=min_s_s, max_features = max_f)\n",
    "                rfc.fit(X_train,Y_train)\n",
    "                \n",
    "                #predict_train = rfc.predict(X_train)\n",
    "                #predict_test  = rfc.predict(X_test)\n",
    "                predict_vali  = rfc.predict(X_vali)\n",
    "                \n",
    "                #train_acc = accuracy_score(np.array(Y_train), np.array(predict_train, dtype=int))\n",
    "                #test_acc  = accuracy_score(np.array(Y_test) , np.array(predict_test , dtype=int))\n",
    "                vali_acc  = accuracy_score(np.array(Y_vali) , np.array(predict_vali , dtype=int))\n",
    "                \n",
    "                if best_accuracy < vali_acc:\n",
    "                    best_model = rfc\n",
    "                    best_accuracy = vali_acc\n",
    "                    best_n_est = n_est\n",
    "                    best_max_f = max_f\n",
    "                    best_min_s_s = min_s_s\n",
    "                    \n",
    "    predict_train = best_model.predict(X_train)\n",
    "    predict_test  = best_model.predict(X_test)\n",
    "    predict_vali  = best_model.predict(X_vali)\n",
    "\n",
    "    train_acc = accuracy_score(np.array(Y_train), np.array(predict_train, dtype=int))\n",
    "    test_acc  = accuracy_score(np.array(Y_test) , np.array(predict_test , dtype=int))\n",
    "    vali_acc  = accuracy_score(np.array(Y_vali) , np.array(predict_vali , dtype=int))\n",
    "    \n",
    "    print('Best n_estimator     :', best_n_est)\n",
    "    print('Best max_feature     :', best_max_f)\n",
    "    print('Best min_sample_split:', best_min_s_s)\n",
    "    print()\n",
    "    print('Train Accuracy     :', train_acc)\n",
    "    print('Test Accuracy      :', test_acc)\n",
    "    print('Validation Accuracy:', vali_acc)\n",
    "    \n",
    "    return best_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c500d30-25dd-429c-bc8b-bcae3d2d7e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "itr\n",
      "Best n_estimator     : 150\n",
      "Best max_feature     : 0.5\n",
      "Best min_sample_split: 10\n",
      "\n",
      "Train Accuracy     : 0.9785169210351692\n",
      "Test Accuracy      : 0.9013492590134926\n",
      "Validation Accuracy: 0.9093321539141973\n",
      "CPU times: user 1h 3min 39s, sys: 1.62 s, total: 1h 3min 40s\n",
      "Wall time: 1h 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc = part_c_random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "5bf21aec-bcb6-4672-a4eb-b64c1c61bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_d_param_senitivity(best_n_est=150, best_max_f = 0.5, best_min_s_s = 10):\n",
    "    d = 50\n",
    "    cols_not_y = ohe_train_data.columns[:-1]\n",
    "    X_train = ohe_train_data.loc[:, cols_not_y]\n",
    "    Y_train = ohe_train_data['y'] == 'yes'\n",
    "    X_test  = ohe_test_data.loc[:, cols_not_y]\n",
    "    Y_test  = ohe_test_data['y'] == 'yes'\n",
    "    X_vali  = ohe_vali_data.loc[:, cols_not_y]\n",
    "    Y_vali  = ohe_vali_data['y'] == 'yes'\n",
    "    \n",
    "    n_estimators = np.array(range(50, 451, 100))\n",
    "    max_features = np.array(range(1, 11,2))/10\n",
    "    min_samples_split = np.array(range(2,12,2))\n",
    "    \n",
    "#     accuracy_for_n_est = []\n",
    "#     for n_est in n_estimators:\n",
    "#         rfc = RandomForestClassifier(n_estimators=n_est ,max_depth=d,min_samples_split=best_min_s_s, max_features = best_max_f)\n",
    "#         rfc.fit(X_train,Y_train)\n",
    "\n",
    "#         predict_train = rfc.predict(X_train)\n",
    "#         predict_test  = rfc.predict(X_test)\n",
    "#         predict_vali  = rfc.predict(X_vali)\n",
    "\n",
    "#         train_acc = accuracy_score(np.array(Y_train), np.array(predict_train, dtype=int))\n",
    "#         test_acc  = accuracy_score(np.array(Y_test) , np.array(predict_test , dtype=int))\n",
    "#         vali_acc  = accuracy_score(np.array(Y_vali) , np.array(predict_vali , dtype=int))\n",
    "#         accuracy_for_n_est.append(vali_acc)\n",
    "        \n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(n_estimators, accuracy_for_n_est)\n",
    "#     plt.title(\"Sensitivity for n_estimators\")\n",
    "#     plt.xlabel(\"n_estimators\")\n",
    "#     plt.ylabel(\"Accuracies\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "#     #fig.savefig(\"Sensitivity_for_n_estimators.png\")\n",
    "    \n",
    "#     accuracy_for_max_f = []\n",
    "#     for max_f in max_features:\n",
    "#         rfc = RandomForestClassifier(n_estimators=best_n_est ,max_depth=d,min_samples_split=best_min_s_s, max_features = max_f)\n",
    "#         rfc.fit(X_train,Y_train)\n",
    "\n",
    "#         predict_train = rfc.predict(X_train)\n",
    "#         predict_test  = rfc.predict(X_test)\n",
    "#         predict_vali  = rfc.predict(X_vali)\n",
    "\n",
    "#         train_acc = accuracy_score(np.array(Y_train), np.array(predict_train, dtype=int))\n",
    "#         test_acc  = accuracy_score(np.array(Y_test) , np.array(predict_test , dtype=int))\n",
    "#         vali_acc  = accuracy_score(np.array(Y_vali) , np.array(predict_vali , dtype=int))\n",
    "#         accuracy_for_max_f.append(vali_acc)\n",
    "        \n",
    "#     fig = plt.figure()\n",
    "#     plt.plot(max_features, accuracy_for_max_f)\n",
    "#     plt.title(\"Sensitivity for Max_features\")\n",
    "#     plt.xlabel(\"max_features\")\n",
    "#     plt.ylabel(\"Accuracies\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    \n",
    "    accuracy_for_min_s_s = []\n",
    "    for min_s_s in min_samples_split:\n",
    "        rfc = RandomForestClassifier(n_estimators=best_n_est ,max_depth=d,min_samples_split=min_s_s, max_features = best_max_f)\n",
    "        rfc.fit(X_train,Y_train)\n",
    "\n",
    "        predict_train = rfc.predict(X_train)\n",
    "        predict_test  = rfc.predict(X_test)\n",
    "        predict_vali  = rfc.predict(X_vali)\n",
    "\n",
    "        train_acc = accuracy_score(np.array(Y_train), np.array(predict_train, dtype=int))\n",
    "        test_acc  = accuracy_score(np.array(Y_test) , np.array(predict_test , dtype=int))\n",
    "        vali_acc  = accuracy_score(np.array(Y_vali) , np.array(predict_vali , dtype=int))\n",
    "        accuracy_for_min_s_s.append(vali_acc)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(min_samples_split, accuracy_for_min_s_s)\n",
    "    plt.title(\"Sensitivity for Min sample split\")\n",
    "    plt.xlabel(\"Min sample split\")\n",
    "    plt.ylabel(\"Accuracies\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71112e6c-16d4-4dae-8200-84185ff988d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "part_d_param_senitivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3a7c6-3698-459d-a9f9-f5e7c0c6be49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8109398-c7b7-4541-8d54-505b65ed5f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4369b-1040-433b-954b-82dcf03baa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a04208-be55-4ab7-a3be-97d3b0066db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "24413471-7f0e-4b38-b1bf-2a8bcb781332",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr:month     , val:no        , pruned?:0    ,p_checked:1 ,#childs:12   \n",
      "total nodes: 4196\n"
     ]
    }
   ],
   "source": [
    "print(std_tree_root)\n",
    "print('total nodes:', std_tree_root.total_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d2ef65a5-f5f9-4b6e-b7ba-691de0ca0649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ohe_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "79fd4afd-0deb-47a7-95e9-8e7c4956c09c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Node Count 297\n"
     ]
    }
   ],
   "source": [
    "node_count =0\n",
    "def count_depth(node, d = 0, count_pruned = True):\n",
    "    d_s = [d]\n",
    "    global node_count\n",
    "    node_count +=1\n",
    "    if node.prune_below and not count_pruned:\n",
    "        return d\n",
    "    for child in node.childs:\n",
    "        d_local = count_depth(child, d+1, count_pruned)\n",
    "        d_s.append(d_local)\n",
    "    return np.max(d_s)\n",
    "print(count_depth(std_tree_root, count_pruned=False))\n",
    "print('Node Count',node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e128876d-abed-41b9-9323-77ea178d39ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_tree(node):\n",
    "    if node.parent == None:\n",
    "        print('Root->',node.attr,node.split_val_p, node.val, node.sub_tree_size)\n",
    "    else:\n",
    "        print('Node:',node.attr, node.split_val_p, node.val, node.sub_tree_size,end = ' ')\n",
    "    if node.childs == []:\n",
    "        return 0\n",
    "    for child in node.childs:\n",
    "        print_tree(child)\n",
    "        print('--B--', end = ' ')\n",
    "        print()\n",
    "    return 0\n",
    "#print_tree(tree_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b617a0-1453-4af3-b3ca-c1badbe9e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
