For Decision Tree
std tree Not pruned --
Nodes: 10574, depth: 18




Train accuracy, depth wise
For Normal train: [88.35987613359876, 88.35987613359876, 89.64001327140014, 89.79761114797611, 90.25934527759345, 91.34041141340411, 92.88044680380447, 94.15505419155055, 95.70614908206149, 97.1355894713559, 98.38531298385313, 99.13735899137359, 99.5686794956868, 99.81198849811989, 99.90599424905994, 99.96405662464056, 99.97235124972352, 99.98064587480646, 99.9834107498341]


Std Tree After Pruning --
Nodes: 5478, depth:  17


For Decision Tree
Ohe Tree Not pruned (This was overfitting a lot but after pruning its much better)--
Nodes: 7889, depth: 37

Train accuracy depth wise-
For Ohe Train: [88.35987613359876, 88.35987613359876, 89.64001327140014, 89.68701614687016, 89.70360539703606, 89.89714664897147, 90.28146427781465, 90.37823490378234, 90.82061490820615, 91.152399911524, 91.51183366511833, 91.98186241981863, 92.60119442601194, 93.23158593231587, 93.81497456314975, 94.38453881884539, 95.05363857553638, 95.67020570670206, 96.27018358770184, 96.77615571776155, 97.2489493474895, 97.685799601858, 98.08117673081176, 98.457199734572, 98.77792523777926, 99.06547224065473, 99.27007299270073, 99.49402786994028, 99.63780137137802, 99.80369387303693, 99.87558062375581, 99.93087812430878, 99.95299712452997, 99.96682149966821, 99.98064587480646, 99.9834107498341, 99.98617562486176, 99.98894049988941]

Ohe Tree After pruning --
Nodes: 4519, depth: 37


Random Forest -----

Best n_estimator     : 50
Best max_feature     : 0.3
Best min_sample_split: 4

Train Accuracy     : 0.9949955761999557
Test Accuracy      : 0.9015704490157045
Validation Accuracy: 0.9082264484741265
CPU times: user 1h 6min 35s, sys: 1.16 s, total: 1h 6min 36s
Wall time: 1h 6min 37s


